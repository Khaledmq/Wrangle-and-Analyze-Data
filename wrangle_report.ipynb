{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Gathering the Data :\n",
    "In a Jupyter Notebook called wrangle act.ipynb, we used the following three pieces of data:\n",
    "a. The \"WeRateDogs\" Twitter feed archive.\n",
    "The file was manually downloaded.\n",
    "Data/twitter archive enhanced.csv is the link.\n",
    "b. Predictions for Tweet Image.\n",
    "This file (image predictions.tsv) was downloaded programmatically using the Requests library and the following URL: https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad image -predictions/image-predictions.tsv\n",
    "c. Using the tweet IDs from the WeRateDogs Twitter archive, use Python's Tweepy library to query the Twitter API for each tweet's JSON data, and save each tweet's entire set of JSON data in a file called tweet json.txt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Assessing the Data :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "a. The values ​​corresponding to the \"tweet_id\" column, which currently exist as \"INT\" values,\n",
    "must be of the \"String\" data type.\n",
    "\n",
    "b. Rows should be deleted if the value is not null to keep only the original\n",
    "Tweets for column data matching: \"in_reply_to_status_id\",\n",
    "\"in_reply_to_user_id\", \"retweeted_status_id\", \"retweeted_status_user_id\",\n",
    "\"retweeted_status_timestamp\".\n",
    "\n",
    "vs. The source contains leftover HTML code.\n",
    "\n",
    "that is to say. Extended URLs are missing in some entries.\n",
    "\n",
    "e. The Doggo, Floofer, Pupper and Puppo variables are present in the data as shown\n",
    "primarily represent a single variable and must be a according to the order rule\n",
    "part of the same column. f. We can see some 'None' objects present in \"doggo\", \"floofer\",\n",
    "\"pupper\" and \"puppo\" to convert to \"NaN\".\n",
    "\n",
    "g. 14 rows are in two categories\n",
    "h. The 'None' object in \"doggo\", \"floofer\", \"pupper\" and \"puppo\" needs to be converted to\n",
    "'NaN'. I. The \"timestamp\" is there as an object, where it should be converted to\n",
    "take advantage of datetime.\n",
    "\n",
    "j. The \"name\" column contains several stop words.\n",
    "\n",
    "k. As seen above, the \"name\" column contains a total of 745 \"None\" strings\n",
    "Present.\n",
    "\n",
    "I. From above we can clearly see that there are a total of 639 double links\n",
    "in the data for the \"expanded_urls\" column.\n",
    "Mr. We can see that a total of 23 notes do not have the denominator value 10, i.e.\n",
    "these many values ​​are not scored out of 10. not. So we can see that a total of 440 entries have a numerator value less than 10.\n",
    "\n",
    "O. From the above result it is quite obvious that we are getting wrong or wrong data\n",
    "according to counters, if it has a decimal value, for all counters\n",
    "in the \"rating_numerator\" column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Cleaning the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Suppressed rows with retweets and unnecessary columns\n",
    "- This was done by suppressing rows of values ​​as non-null entities\n",
    "keep only the original tweets for the following columns:\n",
    "\"in_reply_to_status_id\", \"in_reply_to_user_id\", \"retweeted_status_id\",\n",
    "\"retweeted_status_user_id\", \"retweeted_statud_timestamp\".\n",
    "\n",
    "B. HTML leftovers have been suppressed in the source.\n",
    "\n",
    "C. The \"timestamp\" data type has been replaced by datetime.\n",
    "that is to say. The data type of \"tweet_id\" has been changed to \"string\".\n",
    "\n",
    "E. Removed stop words in \"Name\". f. The values ​​in the \"name\" column have been converted to lowercase.\n",
    "\n",
    "G. Change strings with value 'None' to 'NaN'.\n",
    "- We saw that the \"name\" field had 745 strings of \"None\". - Data for \"doggo\", \"floofer\", \"pupper\" and \"puppo\" had \"None\"\n",
    "Line.\n",
    "H. Fix duplicate links and missing URLs by editing or generating URLs\n",
    "- We found a total of 639 duplicate links in \"expanded_urls\".\n",
    "- We had multiple entries with missing extended URLs.\n",
    "\n",
    "I. Incompatible numerators and denominators have been fixed\n",
    "- Inputs were validated while there was no discarding problem (irrational). - Input was changed when demolition error (including decimal) prevailed.\n",
    "\n",
    "J. Dog phase\n",
    "- Created a single variable.\n",
    "- Corrected double phase when necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Final Data And Report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cleansed data is stored in '/home/workspace/twitter_archive_master.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
